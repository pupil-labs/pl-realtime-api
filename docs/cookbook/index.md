In the next section, we will explore how to use the Pupil Labs Realtime API to track your experiment progress using events. This is particularly useful for monitoring the state of your experiment in real-time and can be integrated into various applications.

Have a look at [Track Your Experiment Progress Using Events](./track-your-experiment-progress-using-events.md)

There are more complex examples and tools that leverage this package, have a look at:

<div class="grid cards" markdown>

- :material-brain:{ .lg .middle } **GPT4-Eyes: AI Vision Assistant**

    ***

    Combines eye tracking with AI for real-time scene understanding and assistance.

    [:octicons-arrow-right-24: Learn More](https://docs.pupil-labs.com/alpha-lab/gpt4-eyes/)

- :material-eye:{ .lg .middle } **Gaze Contingency for Assistive Tech**

    ***

    Practical guide to using gaze as a cursor and for gaze contingent paradigms.

    [:octicons-arrow-right-24: Explore Guide](https://docs.pupil-labs.com/alpha-lab/gaze-contingency-assistive/#a-practical-guide-to-implementing-gaze-contingency-for-assistive-technology)

- :fontawesome-brands-python:{ .lg .middle } **Neon Plugin for PsychoPy**

    ***

    Integrate Neon eye tracking into psychophysics experiments with PsychoPy.

    [:octicons-arrow-right-24: Read Documentation](https://docs.pupil-labs.com/neon/data-collection/psychopy/)

- :octicons-code-24:{ .lg .middle } **More Projects and Tools**

    ***

    Detect object's with YOLO in RealTime.

    [:octicons-arrow-right-24: Explore Further](https://gist.github.com/mikelgg93/d629a77cce9543ef43c30fd8b821c95e)

</div>
